# Work Interactively on a Node

Logging in to one of the TACC clusters will place you on a shared **login node**.
These are shared resources and users should not run applications here (including
Python, Matlab, R, or any other code downloaded from the internet). Instead, these
applications should be run on a **compute node**.

## Determine if You Are on a Login or Compute Node

To determine what type of node you are logged into, use the command **`hostname`**.
The output of **`hostname`** will either show a login node (e.g. `login1`, `login2`),
or it will show a series of letters and numbers (e.g. `nid00015`, `c001-005`)
indicating a compute node. The exact output will vary from cluster to cluster. By
default, the same information is located at the beginning of the command prompt,
as is seen in the next section.

## Connect to a Compute Node

To launch an interactive session on a compute node, use the **`idev`** command. Below
is an example of **`idev`** launching from a login node on Lonestar 5 with the default
options:

```
[login]$ idev
 -> Defaults file    : ~/.idevrc
 -> System           : ls5      
 -> Queue            : development   (idev  default       )
 -> Nodes            : 1             (idev  default       )
 -> Tasks per Node   : 24            (~/.idevrc           )
 -> Time (minutes)   : 30            (idev  default       )
 -> Project          : PROJECT-NAME  (~/.idevrc           )

-----------------------------------------------------------------
          Welcome to the Lonestar 5 Supercomputer
-----------------------------------------------------------------

No reservation for this job
--> Verifying valid submit host (login1)...OK
--> Verifying valid jobname...OK
--> Enforcing max jobs per user...OK
--> Verifying availability of your home dir (/home1/01234/username)...OK
--> Verifying availability of your work dir (/work/01234/username)...OK
--> Verifying availability of your scratch dir (/scratch/01234/username)...OK
--> Verifying valid ssh keys...OK
--> Verifying access to desired queue (development)...OK
--> Verifying job request is within current queue limits...OK
--> Checking available allocation (PROJECT-NAME)...OK
Submitted batch job 2573629

 -> After your idev job begins to run, a command prompt will appear,
 -> and you can begin your interactive development session.
 -> We will report the job status every 4 seconds: (PD=pending, R=running).

 ->job status:  PD
 ->job status:  R

 -> Job is now running on masternode= nid00015...OK
 -> Sleeping for 7 seconds...OK    
 -> Checking to make sure your job has initialized an env for you....OK
 -> Creating interactive terminal session (login) on master node nid00015.

[nid00015]$      # note that command prompt has changed
```

## Useful **`idev`** Options

You can pass options to **`idev`** to control the nature of the interactive job. This
includes number of nodes, number of MPI processes, duration of the session, and
identity of the queue. For example:

```
[login]$ idev -N 1 -p development -m 120
```

The above command will launch a session on one node (`-N 1`) in the development
queue (`-p development`) for a duration of 120 minutes (`-m 120`). A full list of
**`idev`** options can be seen by issuing:

```
[login]$ idev -h
```

## Connect Multiple Terminals to the Same Interactive Session

It may be useful to have multiple terminals connected to the same interactive
session on the same compute node. To do this, first launch a job with idev from
one terminal:

**Terminal 1**
```
[login]$ idev
...
[nid00015]$
```

From the command prompt above, you can see the interactive session launched on a
compute node with hostname **`nid00015`**. From the second terminal, type:

**Terminal 2**
```
[login]$ ssh nid00015
...
[nid00015]$
```

Now both terminals are connected to the same compute node in the interactive
session. When the job ends, or when the first terminal disconnects from the
compute node, the second terminal will also be disconnected automatically.

<br>

---
Return to the [Overview](index.md)
